import cv2
import keyboard
import numpy as np

import matplotlib.pyplot as plt

from WorkingWithDrive import Drive


class Stand:
    def __init__(self, camera):
        self.video = cv2.VideoCapture(camera)

        self.measurements = []

        self.border1, self.border2 = self.get_selected_region(self.get_image())

        self.state = "normal"

        self.drive_is_connected = False
        self.drive = Drive()
        self.encoder_positions = []
        self.check_drive_is_connected()

    def check_drive_is_connected(self):
        if self.drive.connection():
            self.drive_is_connected = True
        if self.drive_is_connected:
            self.drive.turn_on()

    def get_image(self):
        success, image = self.video.read()
        if success:
            return image
        return []

    def get_selected_region(self, image):
        x1, y1, x2, y2 = 0, 0, 0, 0
        draw = False

        def get_mouse_position(event, x, y, flags, param):
            nonlocal x1, y1, x2, y2, draw

            if event == cv2.EVENT_LBUTTONDOWN:
                x1, y1 = x, y
                draw = True

            if event == cv2.EVENT_MOUSEMOVE:
                if draw:
                    img = image.copy()
                    cv2.rectangle(img, (x1, y1), (x, y), (0, 255, 0), 2)
                    cv2.imshow('image', img)

            if event == cv2.EVENT_LBUTTONUP:
                x2, y2 = x, y
                cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
                draw = False

        cv2.namedWindow('image')
        cv2.setMouseCallback('image', get_mouse_position)

        while True:
            cv2.imshow('image', image)
            if cv2.waitKey(1000) & 0xFF == 27:  # выход по нажатию Esc
                break

        cv2.destroyAllWindows()
        return (x1, y1), (x2, y2)

    def get_image_contours(self, image):
        gray_frame = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        img = cv2.medianBlur(gray_frame, 7)
        binary_image = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 5)
        contours, hierarchy = cv2.findContours(binary_image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        img_contours = np.uint8(np.zeros((binary_image.shape[0], binary_image.shape[1])))
        for contour in contours:
            img_contours = cv2.drawContours(img_contours, [contour], -1, (255, 255, 255), 1)

        return img_contours

    def get_y_coordinate(self, bw_image):
        x = (self.border1[0] + self.border2[0]) // 2

        for y in range(self.border1[1], self.border2[1]):
            pixel = bw_image[y][x]
            if pixel == 255 and bw_image[y + 1][x] == 0:

                is_it_white_line = True
                for i in range(100):
                    if bw_image[y][x + i] == 255 and bw_image[y + 1][x + i] == 255 \
                            and bw_image[y - 1][x + i] == 255:
                        is_it_white_line = False
                        break
                if not is_it_white_line:
                    continue
                return y
        return False

    def draw_point(self, image, y):
        x = (self.border1[0] + self.border2[0]) // 2
        img_copy = image.copy()
        cv2.circle(img_copy, (x, y), 2, (0, 255, 0), -1)
        return img_copy

    def draw_line(self, image, y, color):
        img_copy = image.copy()
        cv2.line(img_copy, (0, y), (image.shape[1], y), color, 1)
        return img_copy

    def coordinate_processing(self):
        mes = sorted(list(set(self.measurements)))
        maximum = 0
        minimum = 0
        unacceptable_difference = 6
        for i in range(1, len(mes) - 2):
            if mes[i] - mes[i - 1] < unacceptable_difference \
                    and mes[i + 1] - mes[i] < unacceptable_difference:
                maximum = mes[i - 1]
                break
        for j in range(len(mes) - 1, 1, -1):
            if mes[j] - mes[j - 1] < unacceptable_difference \
                    and mes[j - 1] - mes[j - 2] < unacceptable_difference:
                minimum = mes[j]
                break

        return minimum, maximum

    def normal_state(self):
        if len(self.measurements) > 0:
            self.measurements.clear()
        if len(self.encoder_positions) > 0:
            self.encoder_positions.clear()
        image = self.get_image()
        if len(image) == 0:
            return []
        image_contours = self.get_image_contours(image)
        y = self.get_y_coordinate(image_contours)
        if y:
            image_with_point = self.draw_point(image, y)
            return image_with_point
        return ["y not found"]

    def data_collection_state(self):
        if self.drive_is_connected:
            encoder_position = self.drive.encoder_position
        image = self.get_image()
        if len(image) == 0:
            return []
        image_contours = self.get_image_contours(image)
        y = self.get_y_coordinate(image_contours)
        if y:
            if self.drive_is_connected:
                self.encoder_positions.append(encoder_position)
            self.measurements.append(y)
            y_min, y_max = self.coordinate_processing()
            image_with_point = self.draw_point(image, y)
            image_with_one_line = self.draw_line(image_with_point, y_min, (0, 255, 255))
            image_with_two_line = self.draw_line(image_with_one_line, y_max, (255, 255, 0))
            return image_with_two_line
        return ["y not found"]

    def data_processing_state(self):
        image = self.get_image()
        if len(image) == 0:
            return []
        image_contours = self.get_image_contours(image)
        y = self.get_y_coordinate(image_contours)
        if y:
            y_min, y_max = self.coordinate_processing()
            image_with_line = self.draw_line(image, (y_max + y_min) // 2, (0, 255, 0))
            image_with_line_and_point = self.draw_point(image_with_line, y)
            image_with_one_line = self.draw_line(image_with_line_and_point, y_min, (0, 255, 255))
            image_with_two_line = self.draw_line(image_with_one_line, y_max, (255, 255, 0))
            return image_with_two_line
        return ["y not found"]

    def crop(self, image):
        cropped_image = image[self.border1[1]:self.border2[1], self.border1[0]: self.border2[0]]
        return cropped_image

    def on_key_event(self):
        is_open = cv2.getWindowProperty('video', cv2.WND_PROP_VISIBLE)
        if is_open > 0:
            if self.state == "normal":
                self.state = "collection"
            elif self.state == "collection":
                self.state = "processing"
            elif self.state == "processing" and self.drive_is_connected:
                self.state = "getting into position"
            else:
                self.state = "normal"

    def show_image(self, image, coord):
        crop_img = self.crop(image)
        scaled_image = cv2.resize(crop_img, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)
        cv2.putText(scaled_image, self.state, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)
        cv2.putText(scaled_image, coord, (350, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0),
                    2,
                    cv2.LINE_AA)
        cv2.imshow("video", scaled_image)

    def event_handling_without_drive(self):
        keyboard.add_hotkey('space', self.on_key_event)
        while True:
            if self.state == "collection":
                img = self.data_collection_state()
            elif self.state == "processing":
                self.open_close_plot()
                img = self.data_processing_state()
            elif self.state == "normal":
                self.open_close_plot()
                img = self.normal_state()
            if len(img) == 1:
                continue
            if len(img) == 0:
                break
            self.show_image(img, str(len(self.measurements)))
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    def open_close_plot(self):
        if not plt.fignum_exists(1) and self.state == "processing":
            if self.drive_is_connected:
                plt.plot(self.encoder_positions, self.measurements)
            else:
                plt.plot(self.measurements)
            plt.show(block=False)
            plt.pause(0.5)
        elif (self.state == "normal" or self.state == "getting into position") and plt.fignum_exists(1):
            plt.close()

    def event_handling_with_drive(self):
        ONE_TURN = 20000
        keyboard.add_hotkey('space', self.on_key_event)
        while True:
            if self.state == "collection":
                self.drive.move_to_position(self.drive.encoder_position + ONE_TURN)
                while not self.drive.in_position:
                    img = self.data_collection_state()
                    if len(img) == 1:
                        continue
                    if len(img) == 0:
                        break
                    self.show_image(img, str(self.drive.encoder_position))
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        break
                self.state = "processing"

            if self.state == "processing":
                self.open_close_plot()
                img = self.data_processing_state()
                if len(img) == 1:
                    continue
                if len(img) == 0:
                    break
                self.show_image(img, str(self.drive.encoder_position))
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

            if self.state == "getting into position":
                self.open_close_plot()
                _, y_max = self.coordinate_processing()
                for i in range(len(self.encoder_positions)):
                    if self.measurements[i] == y_max:
                        max_encoder_position = self.encoder_positions[i]
                        break
                self.drive.move_to_position(max_encoder_position)
                while not self.drive.in_position:
                    img = self.data_processing_state()
                    if len(img) == 1:
                        continue
                    if len(img) == 0:
                        break
                    self.show_image(img, str(self.drive.encoder_position))
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        break
                self.state = "normal"

            if self.state == "normal":
                img = self.normal_state()
                if len(img) == 1:
                    continue
                if len(img) == 0:
                    break
                self.show_image(img, str(self.drive.encoder_position))
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

    def event_handling(self):
        if not self.drive_is_connected:
            self.event_handling_without_drive()
        else:
            self.event_handling_with_drive()


stand = Stand("Video2.mp4")
stand.event_handling()
stand.video.release()
cv2.destroyAllWindows()
